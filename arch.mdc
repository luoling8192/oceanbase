---
description: 
globs: 
alwaysApply: false
---
聊天应用记忆管理模块开发文档

概述

本模块为聊天应用设计，支持与大型语言模型（LLM，如 Claude）交互，通过外部 LLM 检测用户消息，判断是否需要存储记忆（如兴趣、学习目标），并通过函数调用更新或召回记忆。模块使用 TypeScript、Drizzle ORM 和 PostgreSQL（pgvector），支持 RAG 检索，未来可迁移到 OceanBase。设计遵循函数式编程，注重类型安全和隐私保护。

目标





检测用户与 LLM 的每条消息，提取需要存储的记忆。



通过函数调用更新记忆（如存储兴趣）或召回相关记忆（如推荐学习资源）。



支持个性化学习，提供因材施教的体验。



确保模块可维护、可扩展，支持数据库迁移。

技术栈





后端：Node.js, h3.js, TypeScript



数据库：PostgreSQL, pgvector（向量搜索）



ORM：Drizzle ORM（类型安全）



LLM：xsai https://xsai.js.org/

系统架构

组件







组件



描述





前端



Vue + vitesee-lite 聊天界面，发送用户消息，显示 LLM 响应。





后端



h3js 服务器，处理消息，调用 LLM 检测记忆，管理数据库操作。





LLM



Claude，分析消息，触发 store_memory 或 retrieve_memories 函数。





数据库



PostgreSQL + pgvector，存储记忆和嵌入，未来切换到 OceanBase。

交互流程





用户通过前端发送消息。



后端将消息转发给 LLM（xsai）。



LLM 分析消息，决定是否调用 store_memory（存储兴趣）或 retrieve_memories（召回相关记忆）。



后端通过 Drizzle ORM 执行数据库操作（存储或检索）。



LLM 使用检索的记忆生成个性化响应，返回前端。



前端显示响应。

记忆管理逻辑

记忆类型





兴趣：用户喜欢的主题（如“TypeScript”）。



学习目标：用户正在学习的技能（如“Vue”）。



知识水平：用户对主题的掌握程度（如“Python: 初级”）。



重要对话点：关键信息（如问题、决策）。

检测机制





外部 LLM 检测：Claude 分析每条消息，基于自然语言理解判断是否包含需要存储的记忆。



函数调用：





store_memory：存储新记忆（如用户说“我喜欢 TypeScript”）。



retrieve_memories：检索相关记忆（如用户问“推荐编程资源”）。



触发条件：





兴趣：检测到“I like”或“I’m interested in”等模式。



学习目标：检测到“I’m learning”或“I want to learn”。



知识水平：检测到疑问句（如“What is recursion?”），推断知识缺口。



重要对话点：检测到明确的问题或决策。

存储与召回





存储：将记忆（用户 ID、类型、内容、嵌入）插入数据库，嵌入通过 xsai-embed 生成。



召回：基于查询嵌入执行向量搜索，返回相关记忆。



RAG 优化：使用 pgvector 的 L2 距离搜索，限制返回 5 条记忆。

数据库设计

Schema

使用 Drizzle ORM 定义 memories 表：

import { pgTable, serial, text, vector, timestamp } from 'drizzle-orm/pg-core';

export const memories = pgTable('memories', {
  id: serial('id').primaryKey(),
  userId: text('user_id').notNull(),
  type: text('type').notNull().$type<'interest' | 'learning_goal' | 'knowledge_level' | 'key_point'>(),
  content: text('content').notNull(),
  embedding: vector('embedding', { dimensions: 1536 }).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
});

索引





为 embedding 添加 HNSW 索引以优化向量搜索：

CREATE INDEX memories_embedding_idx ON memories USING hnsw (embedding vector_l2_ops);

迁移





使用 Drizzle Kit 生成和应用迁移：

npx drizzle-kit generate:pg
npx drizzle-kit migrate:pg

核心实现

环境配置





依赖：

npm install drizzle-orm postgres pgvector ofetch h3 @guiiai/logg
npm install -D drizzle-kit typescript @types/node



环境变量（.env）：

DATABASE_URL=postgresql://user:password@localhost:5432/chat_app
LLM_THINKING_API_KEY=
LLM_THINKING_API_BASEURL=
LLM_THINKING_MODEL=

LLM_TOOL_API_KEY=
LLM_TOOL_API_BASEURL=
LLM_TOOL_MODEL=


记忆检测与函数调用





LLM 配置：Claude 使用函数调用，工具定义如下：

[
  {
    "name": "store_memory",
    "description": "Store a user's memory",
    "parameters": {
      "type": "object",
      "properties": {
        "userId": { "type": "string" },
        "type": { "type": "string", "enum": ["interest", "learning_goal", "knowledge_level", "key_point"] },
        "content": { "type": "string" }
      },
      "required": ["userId", "type", "content"]
    }
  },
  {
    "name": "retrieve_memories",
    "description": "Retrieve relevant memories for a user",
    "parameters": {
      "type": "object",
      "properties": {
        "userId": { "type": "string" },
        "query": { "type": "string" }
      },
      "required": ["userId", "query"]
    }
  }
]

部署与测试

部署





初始化 PostgreSQL，启用 pgvector：

CREATE DATABASE chat_app;
\c chat_app
CREATE EXTENSION vector;



应用迁移：

npx drizzle-kit generate:pg
npx drizzle-kit migrate:pg



启动服务器：

npm run start

测试





存储记忆：

curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"userId": "user1", "message": "I like TypeScript"}'



召回记忆：

curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"userId": "user1", "message": "Recommend programming resources"}'

OceanBase 迁移

步骤





配置 OceanBase 连接：

import { drizzle } from 'drizzle-orm/mysql';
import mysql from 'mysql2/promise';

const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  password: 'password',
  database: 'oceanbase_db',
});
const db = drizzle(connection);



调整 schema，使用 OceanBase 的向量类型。



更新迁移脚本：

npx drizzle-kit generate:mysql
npx drizzle-kit migrate:mysql



测试向量搜索性能。

注意事项





验证 OceanBase 的向量搜索支持。



调整 l2Distance 查询以适配 OceanBase 语法。

潜在问题与优化

性能





问题：LLM API 和向量搜索可能导致延迟。



优化：





使用 Redis 缓存嵌入和记忆。



异步处理消息，优化数据库连接池。

隐私





问题：未加密的记忆可能泄露数据。



优化：





使用 Node.js crypto 模块加密 content 字段。



提供用户删除记忆的接口。

准确性





问题：LLM 可能误判记忆类型。



优化：




定期调整工具定义和提示。



收集用户反馈，优化检测逻辑。

可维护性





问题：复杂逻辑可能难以维护。



优化：





编写 Vitest 单元测试。

最佳实践





类型安全：结合 valibot 和 Drizzle ORM 确保输入和数据库操作安全。



函数式编程：使用纯函数，避免副作用。



错误处理：使用 neverthrow 实现函数式错误处理。



测试：覆盖记忆检测、存储和召回逻辑。

参考





Drizzle ORM Documentation



pgvector GitHub



Hugging Face Inference API



Anthropic Claude API



OceanBase Documentation
